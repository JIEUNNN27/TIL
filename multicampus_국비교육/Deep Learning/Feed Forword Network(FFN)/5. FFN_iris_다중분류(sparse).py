# -*- coding: utf-8 -*-
"""코드연습6 - 아이리스(sparse).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W1Maq1sQcjpyzTdpgJIKNMaDdhohnKZm

어떨 때 바이너리, 어떨 때 스팔스, 어떨 때 카테코리컬 크로스 엔트로피 사용하는지 구분해서 외우기!

```
iris = load_iris()

x_feat = iris['data']
y_target = iris['target'].reshape(-1, 1)

x_train, x_test, y_train, y_test = train_test_split(x_feat, y_target, test_size=0.2)

# 입력층 생성
xInput = Input(batch_shape=(None, x_train.shape[1]))

# 은닉층 생성
hLayer = Dense(10)(xInput)

# 출력층 생성
yOutput = Dense(y_train.shape[1], activation='softmax')(hLayer)

model = Model(xInput, yOutput)
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')
model.fit(x_train, y_train)

```
"""

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import numpy as np

from tensorflow.keras.layers import Input, Dense
from tensorflow.keras import Model

iris = load_iris()
x_feat = iris['data']
y_target = iris['target'].reshape(-1, 1)

#클래스 갯수
n_class = len(set(iris['target']))

x_train, x_test, y_train, y_test = train_test_split(x_feat, y_target, test_size = 0.2)

"""softmax -> sparse
sparse는 one-hot 인코딩이 내부적으로 수행된다.
"""

#입력층
xInput = Input(batch_shape = (None, x_train.shape[1]))
#은닉층
hLayer = Dense(10)(xInput)
#출력층
#yOutput = Dense(y_train.shape[1], activation = "softmax")(hLayer)
#클래스 갯수
yOutput = Dense(n_class, activation = "softmax")(hLayer)

model = Model(xInput, yOutput)

model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam')

model.summary()

model.fit(x_train, y_train, epochs = 100)

y_prob = model.predict(x_test)
#shape 맞춰주기(reshape)
y_pred = np.argmax(y_prob, axis = 1).reshape(-1, 1)

acc = (y_test == y_pred).mean()
print(acc)