# -*- coding: utf-8 -*-
"""8-7-1.custom_metric.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dLlgqSfPQizQC3o1Z97iRD7uu1YarI_r
"""

# custom metric 함수 동작 원리 확인용 코드
import numpy as np
import tensorflow as tf
from sklearn.datasets import load_boston
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.models import Model
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# boston house price 데이터를 가져온다.
boston = load_boston()

x_feat = boston['data']
y_target = boston['target'].reshape(-1, 1)

# 데이터 표준화
f_scaler = StandardScaler()
t_scaler = StandardScaler()

xs_feat = f_scaler.fit_transform(x_feat)
ys_target = t_scaler.fit_transform(y_target)

# 학습 데이터와 시험 데이터를 생성한다.
x_train, x_test, y_train, y_test = train_test_split(xs_feat, ys_target, test_size=0.2)

x_train.shape, x_test.shape, y_train.shape, y_test.shape

# custom metrics
class pearson_corr(tf.keras.metrics.Metric):
    def __init__(self, name="pearson_corr", **kwargs):
        super(pearson_corr, self).__init__(name=name, **kwargs)
        self.y_true_list = []
        self.y_pred_list = []

    def update_state(self, y_true, y_pred, sample_weight=None):
        y_true = tf.reshape(y_true, shape=[-1])
        y_pred = tf.reshape(y_pred, shape=[-1])
        self.y_true_list.append(y_true)
        self.y_pred_list.append(y_pred)

    def result(self):
        y_true = tf.concat(self.y_true_list, -1)
        y_pred = tf.concat(self.y_pred_list, -1)
        corr = self.pearson(y_true, y_pred)
        return corr

    def reset_state(self):
        self.y_true_list = []
        self.y_pred_list = []
        
    def pearson(self, true, pred):
        m_true = true - tf.reduce_mean(true)
        m_pred = pred - tf.reduce_mean(pred)

        bunja = tf.reduce_sum(tf.multiply(m_true, m_pred))
        bunmo = tf.sqrt(tf.multiply(tf.reduce_sum(tf.square(m_true)), tf.reduce_sum(tf.square(m_pred)))) + 1e-12
        return bunja / bunmo

# custom loss
def my_loss(y_true, y_pred):
    return tf.sqrt(tf.square(tf.subtract(y_true, y_pred)))

x_input = Input(batch_shape = (None, x_train.shape[1]))
y_output = Dense(1)(x_input)
model = Model(x_input, y_output)
model.compile(loss=my_loss, 
              metrics=[pearson_corr()], 
              optimizer='adam',
              run_eagerly = True)

hist = model.fit(x_train, y_train, batch_size=4, epochs=50, validation_data=(x_test, y_test))

# loss 확인
plt.plot(hist.history['loss'], label='train')
plt.plot(hist.history['val_loss'], label='test')
plt.title('loss')
plt.legend()
plt.show()

# corr 확인
plt.plot(hist.history['pearson_corr'], label='train')
plt.plot(hist.history['val_pearson_corr'], label='test')
plt.title('correlation')
plt.legend()
plt.show()

y_pred = model.predict(x_test)

y_pred.shape, y_test.shape

# 추정 결과를 산포도로 확인한다.
corr = np.corrcoef(y_test.reshape(-1,), y_pred.reshape(-1,))[0,1]

plt.scatter(y_test, y_pred, marker='o', s=10, c='red')
plt.xlabel('y_test')
plt.ylabel('y_pred')
plt.title('corr =' + str(corr.round(4)))
plt.xlim(-3, 3)
plt.ylim(-3, 3)
plt.show()

y_test

